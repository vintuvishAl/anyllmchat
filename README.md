# ğŸ¤– AnyLLMChat
*The Universal Multi-LLM Chat Application for iOS, Android, and Web*

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)
![Platform](https://img.shields.io/badge/platform-iOS%20%7C%20Android%20%7C%20Web-blue)
![React Native](https://img.shields.io/badge/React_Native-20232A?style=flat&logo=react&logoColor=61DAFB)
![Convex](https://img.shields.io/badge/Convex-FF6B6B?style=flat&logo=convex&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)

> **AnyLLMChat** brings together multiple AI models in one powerful, cross-platform experience. Currently supports OpenAI and Google Gemini models, with more providers coming soon - all from a single, beautifully designed app that works everywhere.nd
*A powerful cross-platform multi-LLM chat application built with Convex and React Native*


## ğŸŒŸ Why Expo/React Native Instead of a Web App?

This LLM chat application is built as a **cross-platform mobile app** rather than a traditional web application for several compelling reasons:

### ğŸ“± **Native Mobile Features**
- **ğŸ“¸ Camera Integration**: Direct access to device camera for image analysis and multimodal AI interactions
- **ğŸ™ï¸ Voice Recording**: Native audio recording capabilities for voice-to-text and audio analysis
- **ğŸ“³ Haptic Feedback**: Rich tactile feedback for enhanced user interaction (implemented with `expo-haptics`)
- **ğŸ“ Location Services**: GPS integration for location-aware AI assistance
- **ğŸ“ Contact Access**: Integration with device contacts for personalized AI responses
- **ğŸ’¾ File System Access**: Direct file upload and management capabilities
- **ğŸ”” Push Notifications**: Real-time notifications for AI responses and chat updates

### ğŸš€ **Performance & User Experience**
- **âš¡ Native Performance**: Smooth animations and transitions using `react-native-reanimated`
- **ğŸ“± Mobile-First Design**: Optimized touch interfaces and gesture recognition
- **ğŸ“Š Better Resource Management**: Efficient memory and battery usage compared to web browsers

### ğŸ¯ **AI-Specific Advantages**
- **ğŸ–¼ï¸ Multimodal Input**: Easy integration of camera, microphone, and file uploads for AI analysis
- **ğŸ“‹ Clipboard Integration**: Seamless text and image sharing between apps
- **ğŸ”— Deep Linking**: Direct app-to-app communication for AI workflows
- **âš¡ Real-time Streaming**: Optimized for continuous AI response streaming
- **ğŸ¨ Rich Media Display**: Better handling of AI-generated images, documents, and media

### ğŸŒ **Cross-Platform Benefits**
- **ğŸ“± iOS + Android + Web**: Single codebase, three platforms
- **ğŸ”„ Consistent Experience**: Same features across all devices
- **ğŸ› ï¸ Easy Distribution**: App stores + web deployment
- **ğŸ“ˆ Better Analytics**: Native app usage tracking and user insights

## ğŸ¯ Perfect Use Cases for This App

- **ğŸ“¸ Visual AI Assistant**: Take photos and get AI analysis instantly
- **ğŸ™ï¸ Voice-Powered Chat**: Speak your questions, get audio responses
- **ğŸ“„ Document Analysis**: Upload files directly from your device for AI processing
- **ğŸ“ Location-Aware AI**: Get contextual help based on where you are
- **ğŸ¤ Personal AI Companion**: Access your contacts, calendar, and files for personalized assistance
- **ğŸ® Interactive AI Games**: Leverage device sensors for immersive AI experiences
- **ğŸ“Š Business AI Tools**: Professional workflows with camera scanning, voice notes, and file management

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ installed
- [Expo CLI](https://docs.expo.dev/get-started/installation/) installed globally
- [Convex account](https://convex.dev) (free tier available)
- AI API keys (OpenAI, Anthropic, or Google)

### 1. Clone and Install
```bash
git clone https://github.com/yourusername/anyllmchat.git
cd anyllmchat
npm install
```

### 2. Set Up Convex Backend
```bash
# Install Convex CLI globally (if not already installed)
npm install -g convex

# Initialize your Convex project
npx convex dev
```

This will:
- Create a new Convex project
### 3. Set up Convex Backend

Initialize and configure your Convex backend:

```bash
npx convex dev
```

This will:
- Create a new Convex project (if first time)
- Generate your deployment URL
- Set up the database schema
- Deploy all backend functions

### 4. Configure API Keys in Convex Dashboard

**Important**: API keys are securely managed in the Convex Dashboard, not in local files.

1. After running `npx convex dev`, go to your **Convex Dashboard**
2. Navigate to **Settings > Environment Variables**
3. Add the following API keys (currently supported):

```
OPENAI_API_KEY=your_openai_key_here
GOOGLE_GENERATIVE_AI_API_KEY=your_google_key_here
```

### 5. Start the Development Server
```bash
# Convex backend runs automatically after `npx convex dev`
# In a new terminal, start Expo
npx expo start
```

### 5. Launch the App
- **ğŸ“± Mobile**: Scan the QR code with Expo Go app
- **ğŸ–¥ï¸ Web**: Press `w` to open in browser
- **ğŸ“± iOS Simulator**: Press `i` (requires Xcode)
- **ğŸ¤– Android Emulator**: Press `a` (requires Android Studio)

## ğŸ¯ Features

### âœ… **Current Features**
- ğŸ’¬ **Multi-Model Chat**: Currently supports **OpenAI** (GPT-4, GPT-3.5-turbo) and **Google Gemini** (Pro, Flash)
- âš¡ **Real-Time Streaming**: Live response streaming with typing indicators  
- ğŸ’¾ **Chat History**: Persistent conversation storage and management
- ğŸ¨ **Beautiful UI**: Dark theme with smooth animations and haptic feedback
- ğŸ“± **Cross-Platform**: Runs on iOS, Android, and web with platform-specific optimizations

### ğŸš§ **Coming Soon** (Ready to implement!)
- ğŸ¤– **More LLM Providers**: Anthropic Claude, Mistral, Cohere, and others
- ğŸ“¸ **Camera Integration**: Photo capture and AI image analysis
- ğŸ™ï¸ **Voice Chat**: Speech-to-text and text-to-speech capabilities
- ğŸ“ **File Upload**: Document analysis and file processing
- ğŸ“ **Location Features**: GPS-based contextual assistance
- ğŸ”” **Push Notifications**: Real-time chat notifications
- ğŸ“Š **Advanced Analytics**: Usage insights and AI performance metrics

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Expo App         â”‚â”€â”€â”€â”€â–¶â”‚    Convex Cloud     â”‚â”€â”€â”€â”€â–¶â”‚    AI Providers     â”‚
â”‚  (React Native)     â”‚     â”‚    (Backend)        â”‚     â”‚  (OpenAI/Claude)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Chat Interface    â”‚     â”‚ â€¢ Real-time DB      â”‚     â”‚ â€¢ GPT-4 / GPT-4o    â”‚
â”‚ â€¢ Camera/Media      â”‚     â”‚ â€¢ AI Agents         â”‚     â”‚ â€¢ Claude 3.5        â”‚
â”‚ â€¢ Voice Recording   â”‚     â”‚ â€¢ Streaming API     â”‚     â”‚ â€¢ Gemini 2.0        â”‚
â”‚ â€¢ File Management   â”‚     â”‚ â€¢ User Management   â”‚     â”‚ â€¢ Custom Models     â”‚
â”‚ â€¢ Push Notificationsâ”‚     â”‚ â€¢ Tool Integration  â”‚     â”‚ â€¢ Tool Calling      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Key Components**

#### **Frontend (Expo/React Native)**
- `ChatView.tsx` - Main chat interface with real-time messaging
- `WelcomeScreen.tsx` - Onboarding and quick actions
- `MessageList.tsx` - Optimized message rendering with FlashList
- `ChatInput.tsx` - Input handling with voice/camera integration
- `ModelSelectorModal.tsx` - AI model switching interface

#### **Backend (Convex)**
- `chat.ts` - Chat management and message handling
- `agents.ts` - AI agent configuration and tool integration  
- `http.ts` - Streaming API endpoint for real-time responses
- `schema.ts` - Database schema for chats, users, and preferences

#### **AI Integration**
- Multiple provider support (OpenAI, Anthropic, Google)
- Streaming response handling
- Tool calling and function execution
- Context management and memory

## ğŸ› ï¸ Development

### **Project Structure**
```
llm-app/
â”œâ”€â”€ app/                 # Expo Router pages
â”œâ”€â”€ components/          # React Native components
â”‚   â”œâ”€â”€ chat/           # Chat-specific components
â”‚   â””â”€â”€ ui/             # Reusable UI components
â”œâ”€â”€ convex/             # Backend functions and schema
â”œâ”€â”€ hooks/              # Custom React hooks
â”œâ”€â”€ constants/          # App constants and themes
â””â”€â”€ assets/             # Images, fonts, and static files
```

### **Testing**
```bash
# Run unit tests
npm test

# Run with coverage
npm run test:coverage

# Run in watch mode
npm run test:watch
```

### **Building for Production**
```bash
# Build for all platforms
npx expo build

# Build for specific platform
npx expo build:ios
npx expo build:android
npx expo build:web
```

## ğŸ¤ Contributing

welcome contributions! This project is a great way to:
- React Native
- Explore AI integration patterns
- Build mobile-first experiences

### **How to Contribute**
1. Fork the repository
2. Create a feature branch
3. Add your improvements
4. Submit a pull request

### **Areas for Contribution**
- ğŸ“¸ Camera and image processing features
- ğŸ™ï¸ Voice and audio capabilities  
- ğŸ”§ Additional AI tools and integrations
- ğŸ¨ UI/UX improvements
- ğŸ“š Documentation and tutorials
- ğŸ§ª Testing and quality assurance

## ğŸ“„ License

MIT License - feel free to use this project as a starting point for your own AI applications!

## ğŸ”— Resources

- [Convex Documentation](https://docs.convex.dev)
- [Expo Documentation](https://docs.expo.dev)
- [React Native Documentation](https://reactnative.dev)

---

**Built with â¤ï¸**
